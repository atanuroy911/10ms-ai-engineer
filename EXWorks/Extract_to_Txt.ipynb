{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For timestamp in text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979ccda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_extracted_text_to_files(\n",
    "    pdf_path: str = \"Data/HSC26-Bangla1st-Paper.pdf\",\n",
    "    start_page: Optional[int] = None,\n",
    "    end_page: Optional[int] = None,\n",
    "    dpi: int = 300,\n",
    "    output_dir: str = \"extracted_text\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract text from PDF using OCR and save to individual .txt files\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        start_page: Starting page number (0-indexed). If None, starts from beginning\n",
    "        end_page: Ending page number (0-indexed, inclusive). If None, goes to end\n",
    "        dpi: DPI for image conversion\n",
    "        output_dir: Directory to save text files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    import os\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        print(f\"üìÅ Created directory: {output_dir}\")\n",
    "    \n",
    "    # Open PDF to get page count\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = len(doc)\n",
    "    doc.close()\n",
    "    \n",
    "    # Set page range\n",
    "    start_page = start_page if start_page is not None else 0\n",
    "    end_page = end_page if end_page is not None else total_pages - 1\n",
    "    \n",
    "    # Validate page range\n",
    "    start_page = max(0, min(start_page, total_pages - 1))\n",
    "    end_page = max(start_page, min(end_page, total_pages - 1))\n",
    "    \n",
    "    print(f\"üíæ Saving extracted text from pages {start_page + 1} to {end_page + 1}\")\n",
    "    print(f\"üìÑ PDF has {total_pages} total pages\")\n",
    "    \n",
    "    # Get base filename for naming\n",
    "    base_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    \n",
    "    # Extract and save text from each page\n",
    "    all_text = []\n",
    "    successful_pages = []\n",
    "    \n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        print(f\"Processing page {page_num + 1}/{total_pages}...\")\n",
    "        \n",
    "        # Extract text using OCR\n",
    "        raw_text = extract_text_with_ocr(pdf_path, page_num, dpi)\n",
    "        cleaned_text = preprocess_bengali_text(raw_text)\n",
    "        \n",
    "        if cleaned_text.strip():\n",
    "            # Save individual page text\n",
    "            page_filename = f\"{base_name}_page_{page_num + 1:03d}.txt\"\n",
    "            page_filepath = os.path.join(output_dir, page_filename)\n",
    "            \n",
    "            with open(page_filepath, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Page {page_num + 1} - Raw Text:\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\")\n",
    "                f.write(raw_text)\n",
    "                f.write(\"\\n\\n\" + \"=\" * 50 + \"\\n\")\n",
    "                f.write(f\"Page {page_num + 1} - Cleaned Text:\\n\")\n",
    "                f.write(\"=\" * 50 + \"\\n\")\n",
    "                f.write(cleaned_text)\n",
    "                f.write(\"\\n\\n\" + \"=\" * 50 + \"\\n\")\n",
    "            \n",
    "            all_text.append(f\"=== PAGE {page_num + 1} ===\\n{cleaned_text}\\n\")\n",
    "            successful_pages.append(page_num + 1)\n",
    "            \n",
    "            print(f\"‚úÖ Saved: {page_filename} ({len(cleaned_text)} characters)\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Page {page_num + 1}: No text extracted, skipping file creation\")\n",
    "    \n",
    "    # Save combined text file\n",
    "    if all_text:\n",
    "        combined_filename = f\"{base_name}_combined_pages_{start_page + 1}-{end_page + 1}.txt\"\n",
    "        combined_filepath = os.path.join(output_dir, combined_filename)\n",
    "        \n",
    "        with open(combined_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Combined Text from {pdf_path}\\n\")\n",
    "            f.write(f\"Pages: {start_page + 1} to {end_page + 1}\\n\")\n",
    "            f.write(f\"Extraction Date: {pd.Timestamp.now()}\\n\")\n",
    "            f.write(f\"DPI: {dpi}\\n\")\n",
    "            f.write(f\"Total Pages Processed: {len(successful_pages)}\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            \n",
    "            for text in all_text:\n",
    "                f.write(text)\n",
    "                f.write(\"\\n\" + \"-\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        print(f\"\\nüìÑ Combined file saved: {combined_filename}\")\n",
    "        print(f\"üìä Successfully processed {len(successful_pages)} pages\")\n",
    "        print(f\"üìÅ All files saved in: {output_dir}\")\n",
    "        \n",
    "        # Create summary file\n",
    "        summary_filename = f\"{base_name}_extraction_summary.txt\"\n",
    "        summary_filepath = os.path.join(output_dir, summary_filename)\n",
    "        \n",
    "        with open(summary_filepath, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"Text Extraction Summary\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\")\n",
    "            f.write(f\"Source PDF: {pdf_path}\\n\")\n",
    "            f.write(f\"Page Range: {start_page + 1} to {end_page + 1}\\n\")\n",
    "            f.write(f\"Total Pages in PDF: {total_pages}\\n\")\n",
    "            f.write(f\"Successfully Processed: {len(successful_pages)} pages\\n\")\n",
    "            f.write(f\"DPI Setting: {dpi}\\n\")\n",
    "            f.write(f\"Extraction Date: {pd.Timestamp.now()}\\n\")\n",
    "            f.write(f\"Output Directory: {output_dir}\\n\\n\")\n",
    "            \n",
    "            f.write(\"Successfully Processed Pages:\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            for page in successful_pages:\n",
    "                f.write(f\"Page {page}\\n\")\n",
    "            \n",
    "            f.write(f\"\\nFiles Created:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(f\"- Individual page files: {len(successful_pages)} files\\n\")\n",
    "            f.write(f\"- Combined text file: {combined_filename}\\n\")\n",
    "            f.write(f\"- Summary file: {summary_filename}\\n\")\n",
    "        \n",
    "        print(f\"üìã Summary saved: {summary_filename}\")\n",
    "        \n",
    "        return successful_pages, output_dir\n",
    "    else:\n",
    "        print(\"‚ùå No text was extracted from any pages!\")\n",
    "        return [], output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ Extract and save text to .txt files for backup and analysis\n",
    "# This will create individual page files and a combined file\n",
    "\n",
    "# Example 1: Save text from the same page range used for vector store\n",
    "successful_pages, output_dir = save_extracted_text_to_files(\n",
    "    pdf_path=\"Data/HSC26-Bangla1st-Paper.pdf\",\n",
    "    start_page=42,    # Same as vector store range\n",
    "    end_page=49,      # Same as vector store range\n",
    "    dpi=400,          # Same DPI for consistency\n",
    "    output_dir=\"extracted_text_bengali\"  # Custom directory name\n",
    ")\n",
    "\n",
    "print(f\"\\nüéâ Text extraction completed!\")\n",
    "print(f\"üìÅ Files saved in: {output_dir}\")\n",
    "print(f\"üìÑ Successfully processed: {len(successful_pages)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447483b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Additional utility functions for text file management\n",
    "\n",
    "def list_extracted_text_files(output_dir: str = \"extracted_text_bengali\"):\n",
    "    \"\"\"\n",
    "    List all extracted text files in the directory\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        print(f\"‚ùå Directory {output_dir} does not exist\")\n",
    "        return\n",
    "    \n",
    "    files = [f for f in os.listdir(output_dir) if f.endswith('.txt')]\n",
    "    \n",
    "    if not files:\n",
    "        print(f\"üìÅ No .txt files found in {output_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìÑ Found {len(files)} text files in {output_dir}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Separate different types of files\n",
    "    page_files = [f for f in files if '_page_' in f]\n",
    "    combined_files = [f for f in files if '_combined_' in f]\n",
    "    summary_files = [f for f in files if '_summary' in f]\n",
    "    \n",
    "    if page_files:\n",
    "        print(f\"\\nüìÑ Individual Page Files ({len(page_files)}):\")\n",
    "        for f in sorted(page_files):\n",
    "            file_path = os.path.join(output_dir, f)\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  - {f} ({size:,} bytes)\")\n",
    "    \n",
    "    if combined_files:\n",
    "        print(f\"\\nüìö Combined Files ({len(combined_files)}):\")\n",
    "        for f in combined_files:\n",
    "            file_path = os.path.join(output_dir, f)\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  - {f} ({size:,} bytes)\")\n",
    "    \n",
    "    if summary_files:\n",
    "        print(f\"\\nüìã Summary Files ({len(summary_files)}):\")\n",
    "        for f in summary_files:\n",
    "            file_path = os.path.join(output_dir, f)\n",
    "            size = os.path.getsize(file_path)\n",
    "            print(f\"  - {f} ({size:,} bytes)\")\n",
    "\n",
    "def read_extracted_page(page_num: int, output_dir: str = \"extracted_text_bengali\", show_raw: bool = False):\n",
    "    \"\"\"\n",
    "    Read and display extracted text from a specific page\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    # Find the page file\n",
    "    files = os.listdir(output_dir) if os.path.exists(output_dir) else []\n",
    "    page_file = None\n",
    "    \n",
    "    for f in files:\n",
    "        if f'_page_{page_num:03d}.txt' in f:\n",
    "            page_file = f\n",
    "            break\n",
    "    \n",
    "    if not page_file:\n",
    "        print(f\"‚ùå Page {page_num} text file not found in {output_dir}\")\n",
    "        return\n",
    "    \n",
    "    file_path = os.path.join(output_dir, page_file)\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    print(f\"üìÑ Content from Page {page_num}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if show_raw:\n",
    "        print(content)\n",
    "    else:\n",
    "        # Show only cleaned text\n",
    "        parts = content.split(\"Cleaned Text:\")\n",
    "        if len(parts) > 1:\n",
    "            cleaned_part = parts[1].split(\"=\" * 50)[0].strip()\n",
    "            print(cleaned_part[:1000] + \"...\" if len(cleaned_part) > 1000 else cleaned_part)\n",
    "        else:\n",
    "            print(content[:1000] + \"...\" if len(content) > 1000 else content)\n",
    "\n",
    "# Example usage:\n",
    "# list_extracted_text_files()\n",
    "# read_extracted_page(43)  # Read page 43 content"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
