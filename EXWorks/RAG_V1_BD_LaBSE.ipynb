{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ba43da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Bengali RAG system with OCR and LaBSE embeddings\n",
    "# Run this cell first to install all necessary packages\n",
    "# !pip install langchain-openai\n",
    "# !pip install langchain-community\n",
    "# !pip install langchain-huggingface\n",
    "# !pip install chromadb\n",
    "# !pip install sentence-transformers\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    "# !pip install pymupdf  # For PDF to image conversion\n",
    "# !pip install pytesseract  # OCR engine\n",
    "# !pip install Pillow  # Image processing\n",
    "# !pip install opencv-python  # Image preprocessing\n",
    "# !pip install numpy\n",
    "\n",
    "# Note: You also need to install Tesseract OCR separately:\n",
    "# Download from: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "# Make sure to install Bengali language data (ben.traineddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df3d43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.schema import Document\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import fitz  # PyMuPDF for PDF to image\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab229eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up OpenAI API key\n",
    "# You can get your API key from: https://platform.openai.com/api-keys\n",
    "openai_api_key = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc96af77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bengali language support is available in Tesseract\n"
     ]
    }
   ],
   "source": [
    "# Configure Tesseract OCR\n",
    "# Make sure you have installed Tesseract and Bengali language data\n",
    "# Download Tesseract: https://github.com/UB-Mannheim/tesseract/wiki\n",
    "# Bengali language data should be in tessdata folder\n",
    "\n",
    "# Set Tesseract path (adjust according to your installation)\n",
    "# For Windows: \n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# For Linux/Mac, it's usually in PATH, so you might not need to set this\n",
    "# pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
    "\n",
    "# Test if Bengali is available\n",
    "try:\n",
    "    available_langs = pytesseract.get_languages()\n",
    "    if 'ben' in available_langs:\n",
    "        print(\"✅ Bengali language support is available in Tesseract\")\n",
    "    else:\n",
    "        print(\"❌ Bengali language support not found. Please install Bengali traineddata.\")\n",
    "        print(\"Download ben.traineddata from: https://github.com/tesseract-ocr/tessdata\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Tesseract configuration issue: {e}\")\n",
    "    print(\"Please make sure Tesseract is properly installed and configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bad20116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_ocr(image_array: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess image for better OCR results\n",
    "    \"\"\"\n",
    "    # Convert to grayscale if needed\n",
    "    if len(image_array.shape) == 3:\n",
    "        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = image_array\n",
    "    \n",
    "    # Increase contrast and brightness\n",
    "    alpha = 1.2  # Contrast control\n",
    "    beta = 10    # Brightness control\n",
    "    adjusted = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(adjusted, (1, 1), 0)\n",
    "    \n",
    "    # Apply threshold to get binary image\n",
    "    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Morphological operations to clean up the image\n",
    "    kernel = np.ones((1, 1), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def pdf_page_to_image(pdf_path: str, page_num: int, dpi: int = 300) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Convert a specific PDF page to high-resolution image\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc[page_num]\n",
    "    \n",
    "    # Create transformation matrix for high DPI\n",
    "    mat = fitz.Matrix(dpi/72, dpi/72)\n",
    "    \n",
    "    # Render page to pixmap\n",
    "    pix = page.get_pixmap(matrix=mat)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    img_data = pix.tobytes(\"ppm\")\n",
    "    image = Image.open(io.BytesIO(img_data))\n",
    "    \n",
    "    doc.close()\n",
    "    return image\n",
    "\n",
    "def extract_text_with_ocr(pdf_path: str, page_num: int, dpi: int = 300) -> str:\n",
    "    \"\"\"\n",
    "    Extract text from PDF page using OCR\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert PDF page to image\n",
    "        image = pdf_page_to_image(pdf_path, page_num, dpi)\n",
    "        \n",
    "        # Convert PIL image to numpy array\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # Preprocess image for better OCR\n",
    "        processed_img = preprocess_image_for_ocr(img_array)\n",
    "        \n",
    "        # Convert back to PIL Image for pytesseract\n",
    "        pil_image = Image.fromarray(processed_img)\n",
    "        \n",
    "        # OCR configuration for Bengali\n",
    "        custom_config = r'--oem 3 --psm 6 -l ben+eng'  # Bengali + English\n",
    "        \n",
    "        # Extract text using OCR\n",
    "        text = pytesseract.image_to_string(pil_image, config=custom_config)\n",
    "        \n",
    "        return text.strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from page {page_num}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def preprocess_bengali_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess Bengali text for better processing\n",
    "    \"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove common OCR artifacts\n",
    "    text = re.sub(r'[^\\u0980-\\u09FF\\u0020-\\u007F\\u2000-\\u206F\\u2E00-\\u2E7F]', ' ', text)\n",
    "    \n",
    "    # Clean up punctuation spacing\n",
    "    text = re.sub(r'\\s+([।,;:!?])', r'\\1', text)\n",
    "    text = re.sub(r'([।,;:!?])\\s*', r'\\1 ', text)\n",
    "    \n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b29e976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading LaBSE embeddings (this may take a moment on first run)...\n",
      "✅ LaBSE embeddings loaded successfully!\n",
      "📊 Model info:\n",
      "   - Model: sentence-transformers/LaBSE\n",
      "   - Languages: 109+ including Bengali, English, Hindi, etc.\n",
      "   - Embedding dimension: 768\n",
      "   - Optimized for: Cross-lingual semantic similarity\n"
     ]
    }
   ],
   "source": [
    "import io  # For BytesIO\n",
    "\n",
    "# Configure LaBSE embeddings for multilingual support\n",
    "def create_labse_embeddings():\n",
    "    \"\"\"\n",
    "    Create LaBSE (Language-agnostic BERT Sentence Embeddings) for multilingual support\n",
    "    LaBSE is specifically designed for cross-lingual tasks and works excellently with Bengali\n",
    "    \"\"\"\n",
    "    print(\"🔄 Loading LaBSE embeddings (this may take a moment on first run)...\")\n",
    "    \n",
    "    # LaBSE model from sentence-transformers\n",
    "    # This model supports 109+ languages including Bengali\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/LaBSE\",\n",
    "        model_kwargs={\n",
    "            'device': 'cuda',  # Use 'cuda' if you have GPU\n",
    "            'trust_remote_code': False\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            'normalize_embeddings': True,  # Important for similarity search\n",
    "            'batch_size': 32,\n",
    "            'show_progress_bar': True\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"✅ LaBSE embeddings loaded successfully!\")\n",
    "    print(\"📊 Model info:\")\n",
    "    print(\"   - Model: sentence-transformers/LaBSE\")\n",
    "    print(\"   - Languages: 109+ including Bengali, English, Hindi, etc.\")\n",
    "    print(\"   - Embedding dimension: 768\")\n",
    "    print(\"   - Optimized for: Cross-lingual semantic similarity\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Test LaBSE embeddings\n",
    "labse_embeddings = create_labse_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c461bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_bengali_documents_with_ocr_labse(\n",
    "    pdf_path: str = \"Data/HSC26-Bangla1st-Paper.pdf\",\n",
    "    start_page: Optional[int] = None,\n",
    "    end_page: Optional[int] = None,\n",
    "    dpi: int = 300,\n",
    "    use_gpu: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Ingest Bengali PDF documents using OCR and create vector store with LaBSE embeddings\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        start_page: Starting page number (0-indexed). If None, starts from beginning\n",
    "        end_page: Ending page number (0-indexed, inclusive). If None, goes to end\n",
    "        dpi: DPI for image conversion (higher = better quality but slower)\n",
    "        use_gpu: Whether to use GPU for embeddings (requires CUDA)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open PDF to get page count\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = len(doc)\n",
    "    doc.close()\n",
    "    \n",
    "    # Set page range\n",
    "    start_page = start_page if start_page is not None else 0\n",
    "    end_page = end_page if end_page is not None else total_pages - 1\n",
    "    \n",
    "    # Validate page range\n",
    "    start_page = max(0, min(start_page, total_pages - 1))\n",
    "    end_page = max(start_page, min(end_page, total_pages - 1))\n",
    "    \n",
    "    print(f\"🔄 Processing pages {start_page + 1} to {end_page + 1} (total: {end_page - start_page + 1} pages)\")\n",
    "    print(f\"📄 PDF has {total_pages} total pages\")\n",
    "    print(f\"🤖 Using LaBSE embeddings (multilingual BERT)\")\n",
    "    print(f\"🔧 GPU acceleration: {'Enabled' if use_gpu else 'Disabled (CPU)'}\")\n",
    "    \n",
    "    # Extract text from each page using OCR\n",
    "    documents = []\n",
    "    \n",
    "    for page_num in range(start_page, end_page + 1):\n",
    "        print(f\"\\n📖 Processing page {page_num + 1}/{total_pages}...\")\n",
    "        \n",
    "        # Extract text using OCR\n",
    "        text = extract_text_with_ocr(pdf_path, page_num, dpi)\n",
    "        \n",
    "        if text.strip():  # Only add if text was extracted\n",
    "            # Preprocess Bengali text\n",
    "            cleaned_text = preprocess_bengali_text(text)\n",
    "            \n",
    "            if cleaned_text:  # Only add if cleaning didn't remove everything\n",
    "                # Create document with metadata\n",
    "                doc = Document(\n",
    "                    page_content=cleaned_text,\n",
    "                    metadata={\n",
    "                        \"source\": pdf_path,\n",
    "                        \"page\": page_num + 1,  # 1-indexed for user display\n",
    "                        \"extraction_method\": \"OCR\",\n",
    "                        \"dpi\": dpi,\n",
    "                        \"embedding_model\": \"LaBSE\",\n",
    "                        \"text_length\": len(cleaned_text)\n",
    "                    }\n",
    "                )\n",
    "                documents.append(doc)\n",
    "                print(f\"   ✅ Extracted {len(cleaned_text)} characters\")\n",
    "            else:\n",
    "                print(f\"   ⚠️ No valid text after cleaning\")\n",
    "        else:\n",
    "            print(f\"   ❌ No text extracted\")\n",
    "    \n",
    "    if not documents:\n",
    "        print(\"❌ No text was extracted from any pages!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\n📄 Total documents created: {len(documents)}\")\n",
    "    \n",
    "    # Split the documents with optimized settings for Bengali\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,   # Optimized for LaBSE (BERT-based models work well with shorter chunks)\n",
    "        chunk_overlap=100,  # Good overlap for context preservation\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "        separators=[\n",
    "            \"\\n\\n\",  # Paragraph breaks\n",
    "            \"\\n\",    # Line breaks\n",
    "            \"।\",     # Bengali sentence end (dari)\n",
    "            \"?\",     # Question mark\n",
    "            \"!\",     # Exclamation\n",
    "            \".\",     # Period\n",
    "            \" \",     # Space\n",
    "            \"\",      # Character level\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"📝 Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "    \n",
    "    # Create LaBSE embeddings\n",
    "    print(f\"🔄 Creating LaBSE embeddings...\")\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/LaBSE\",\n",
    "        model_kwargs={\n",
    "            'device': 'cpu' if use_gpu else 'cpu',\n",
    "            'trust_remote_code': False\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            'normalize_embeddings': True,\n",
    "            'batch_size': 16,  # Smaller batch size for stability\n",
    "            # 'show_progress_bar': True\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=chunks, \n",
    "        embedding=embedding, \n",
    "        persist_directory=\"./bengali_chroma_db_labse\"  # Directory for LaBSE embeddings\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Bengali document ingestion with OCR and LaBSE embeddings completed!\")\n",
    "    print(f\"🎯 Vector store saved to: ./bengali_chroma_db_labse\")\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23879a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Processing pages 43 to 49 (total: 7 pages)\n",
      "📄 PDF has 49 total pages\n",
      "🤖 Using LaBSE embeddings (multilingual BERT)\n",
      "🔧 GPU acceleration: Enabled\n",
      "\n",
      "📖 Processing page 43/49...\n",
      "   ✅ Extracted 1906 characters\n",
      "\n",
      "📖 Processing page 44/49...\n",
      "   ✅ Extracted 1429 characters\n",
      "\n",
      "📖 Processing page 45/49...\n",
      "   ✅ Extracted 2208 characters\n",
      "\n",
      "📖 Processing page 46/49...\n",
      "   ✅ Extracted 2221 characters\n",
      "\n",
      "📖 Processing page 47/49...\n",
      "   ✅ Extracted 2218 characters\n",
      "\n",
      "📖 Processing page 48/49...\n",
      "   ✅ Extracted 1430 characters\n",
      "\n",
      "📖 Processing page 49/49...\n",
      "   ✅ Extracted 1068 characters\n",
      "\n",
      "📄 Total documents created: 7\n",
      "📝 Split 7 documents into 40 chunks.\n",
      "🔄 Creating LaBSE embeddings...\n",
      "✅ Bengali document ingestion with OCR and LaBSE embeddings completed!\n",
      "🎯 Vector store saved to: ./bengali_chroma_db_labse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x25fe73a35f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this once to create the vector store for Bengali documents using OCR and LaBSE embeddings\n",
    "# You can specify page ranges to process only specific pages\n",
    "\n",
    "# Example 1: Process all pages with LaBSE (CPU)\n",
    "# ingest_bengali_documents_with_ocr_labse(\"Data/HSC26-Bangla1st-Paper.pdf\")\n",
    "\n",
    "# Example 2: Process pages 5 to 10 with GPU acceleration (if available)\n",
    "# ingest_bengali_documents_with_ocr_labse(\n",
    "#     \"Data/HSC26-Bangla1st-Paper.pdf\", \n",
    "#     start_page=4, \n",
    "#     end_page=9,\n",
    "#     use_gpu=True  # Enable if you have CUDA-compatible GPU\n",
    "# )\n",
    "\n",
    "# Example 3: Process from page 43 to 49 with high DPI\n",
    "ingest_bengali_documents_with_ocr_labse(\n",
    "    pdf_path=\"Data/HSC26-Bangla1st-Paper.pdf\",\n",
    "    start_page=42,    # Start from page 43 (0-indexed)\n",
    "    end_page=49,     # End at page 50 (0-indexed, inclusive)\n",
    "    dpi=400,         # Higher DPI for better OCR quality\n",
    "    use_gpu=True    # Set to True if you have GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2098125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Previewing OCR extraction for page 43\n",
      "============================================================\n",
      "📄 Raw text length: 1914 characters\n",
      "🧹 Cleaned text length: 1912 characters\n",
      "\n",
      "============================================================\n",
      "📝 Raw OCR Output (first 500 chars):\n",
      "----------------------------------------\n",
      "1911\n",
      "প্রশ্থ- ২: পড়াশুনা শেষ করে সবিতা এখন গ্রামের একটি সরকারি প্রাইমারি স্কুলে শিক্ষকতা করেন। বছর\n",
      "কয়েক আগে শহরের এক ধনী ব্যবসায়ীর ছেলের সাথে তার বিবাহ স্থির হয়। পাত্রপক্ষ বিয়েতে মোটা অঙ্কের\n",
      "যৌতুক দাবি করলে তার আত্মসম্মানে আঘাত লাগে। সবিতা নিজেই যৌতুককে প্রত্যাখ্যান করে বিয়ে না করার\n",
      "সিদ্ধান্তে অটল থাকেন। পিতামাতা ও সহকর্মীদের অনেক অনুরোধ সত্ত্বেও তিনি তার চিন্তা-চেতনায় কোনো\n",
      "পরিবর্তন আনেননি। তিনি ছাত্র-ছাত্রীদের প্রাণ। মায়ের মতো ভালোবাসা দিয়ে আগলে রাখেন সবাইকে। তিনি\n",
      "বলেন, \"দেশকে মাতৃজ্ঞান\n",
      "\n",
      "============================================================\n",
      "✨ Cleaned Text (first 500 chars):\n",
      "----------------------------------------\n",
      "1911 প্রশ্থ- ২: পড়াশুনা শেষ করে সবিতা এখন গ্রামের একটি সরকারি প্রাইমারি স্কুলে শিক্ষকতা করেন  বছর কয়েক আগে শহরের এক ধনী ব্যবসায়ীর ছেলের সাথে তার বিবাহ স্থির হয়  পাত্রপক্ষ বিয়েতে মোটা অঙ্কের যৌতুক দাবি করলে তার আত্মসম্মানে আঘাত লাগে  সবিতা নিজেই যৌতুককে প্রত্যাখ্যান করে বিয়ে না করার সিদ্ধান্তে অটল থাকেন  পিতামাতা ও সহকর্মীদের অনেক অনুরোধ সত্ত্বেও তিনি তার চিন্তা-চেতনায় কোনো পরিবর্তন আনেননি  তিনি ছাত্র-ছাত্রীদের প্রাণ  মায়ের মতো ভালোবাসা দিয়ে আগলে রাখেন সবাইকে  তিনি বলেন, \"দেশকে মাতৃজ্ঞান\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('1911\\nপ্রশ্থ- ২: পড়াশুনা শেষ করে সবিতা এখন গ্রামের একটি সরকারি প্রাইমারি স্কুলে শিক্ষকতা করেন। বছর\\nকয়েক আগে শহরের এক ধনী ব্যবসায়ীর ছেলের সাথে তার বিবাহ স্থির হয়। পাত্রপক্ষ বিয়েতে মোটা অঙ্কের\\nযৌতুক দাবি করলে তার আত্মসম্মানে আঘাত লাগে। সবিতা নিজেই যৌতুককে প্রত্যাখ্যান করে বিয়ে না করার\\nসিদ্ধান্তে অটল থাকেন। পিতামাতা ও সহকর্মীদের অনেক অনুরোধ সত্ত্বেও তিনি তার চিন্তা-চেতনায় কোনো\\nপরিবর্তন আনেননি। তিনি ছাত্র-ছাত্রীদের প্রাণ। মায়ের মতো ভালোবাসা দিয়ে আগলে রাখেন সবাইকে। তিনি\\nবলেন, \"দেশকে মাতৃজ্ঞানে সেবা করা, দেশকে ভালোবাসা প্রত্যেকের কর্তব্য।\" পরহিতে জীবন উৎসর্গ করাই\\nতার ধর্ম।\\n\\n[ঢাকা বোর্ড: ২০২২]\\nক. অনুপমের বন্ধু হরিশ কোথায় কাজ করে?\\nখ. \"এইটে একবার পরখ করিয়া দেখো।”- ব্যাখ্যা কর।\\nগ. \"উদ্দীপকের \\'সবিতা\\' ও \"অপরিচিতা\\' গল্পের \\'কল্যাণী\\' উভয়েই যৌতুকের শিকার।\"- মন্তব্যটি\\nবিশ্লেষণ কর।\\nঘ. \"সবিতার দেশপ্রেম কল্যাণীর মাতৃআজ্ঞার সাথে একই সূত্রে গাথা ।\"- উক্তিটির যথার্থতা বিচার কর।\\nসমাধান:\\nক. অনুপমের বন্ধু হরিশ কানপুরে কাজ করে।\\nখ. শস্তুনাথ সেন আলোচ্য উক্তির মধ্য দিয়ে একজোড়া এয়ারিং সেকরার হাতে দিয়ে তা খাঁটি সোনার কি না\\nপরখ করে দেখতে বলেছেন। \\'অপরিচিতা\\' গল্পের অনুপমের সঙ্গে শস্তুনাথ সেনের কন্যা কল্যাণীর বিয়ে ঠিক\\nকল্যাণীর শরীর থেকে খুলে পরীক্ষা করান অনুপমের মামা। তখন শন্তুনাথ সেন এক জোড়া এয়ারিং এগিয়ে\\nদেন সেকরার হাতে তা পরখ করে দেখার জন্য। কেননা সেটা ছিল অনুপমের মামার দেওয়া বিলাতি জিনিস,\\nযাতে সোনার ভাগ আছে সামান্যই।\\nগ. \"উদ্দীপকের \\'সবিতা\\' ও \\'অপরিচিতা\\' গল্পের \\'কল্যাণী\\' উভয়েই যৌতুকের শিকার।\"- মন্তব্যটি যথার্থ।\\nযৌতুকপ্রথা একটি সামাজিক ব্যাধি। এটি আমাদের সমাজে ভয়াল রূপ ধারণ করেছে। বরপক্ষের দাবি পূরণ\\nকরতে কন্যার পিতাকে কখনো কখনো সর্বস্বান্ত হতে হয়। বিয়েতে যারা যৌতুক দাবি করে তারা\\nআত্মসম্মানবোধহীন অমানবিক প্রকৃতির লোক।\\nউদ্দীপকে যৌতুকের জন্য বিয়ে ভেঙে যাওয়া এবং যৌতুক দিয়ে বিয়ে না করে আত্মনির্ভরশীল হয়ে\\nমানবকল্যাণে আত্মনিবেদনের দিকটি প্রতিফলিত হয়েছে। এখানে যৌতুককে প্রত্যাখ্যান করে বিয়ে না করার\\nসিদ্ধান্তে সবিতার অটল থাকার কথা বলা হয়েছে। উদ্দীপকের এ বিষয়টি \\'অপরিচিতা\\' গল্পের কল্যাণীর বিয়ে\\n\\n43',\n",
       " '1911 প্রশ্থ- ২: পড়াশুনা শেষ করে সবিতা এখন গ্রামের একটি সরকারি প্রাইমারি স্কুলে শিক্ষকতা করেন  বছর কয়েক আগে শহরের এক ধনী ব্যবসায়ীর ছেলের সাথে তার বিবাহ স্থির হয়  পাত্রপক্ষ বিয়েতে মোটা অঙ্কের যৌতুক দাবি করলে তার আত্মসম্মানে আঘাত লাগে  সবিতা নিজেই যৌতুককে প্রত্যাখ্যান করে বিয়ে না করার সিদ্ধান্তে অটল থাকেন  পিতামাতা ও সহকর্মীদের অনেক অনুরোধ সত্ত্বেও তিনি তার চিন্তা-চেতনায় কোনো পরিবর্তন আনেননি  তিনি ছাত্র-ছাত্রীদের প্রাণ  মায়ের মতো ভালোবাসা দিয়ে আগলে রাখেন সবাইকে  তিনি বলেন, \"দেশকে মাতৃজ্ঞানে সেবা করা, দেশকে ভালোবাসা প্রত্যেকের কর্তব্য \" পরহিতে জীবন উৎসর্গ করাই তার ধর্ম  [ঢাকা বোর্ড: ২০২২] ক. অনুপমের বন্ধু হরিশ কোথায় কাজ করে? খ. \"এইটে একবার পরখ করিয়া দেখো ”- ব্যাখ্যা কর  গ. \"উদ্দীপকের \\'সবিতা\\' ও \"অপরিচিতা\\' গল্পের \\'কল্যাণী\\' উভয়েই যৌতুকের শিকার \"- মন্তব্যটি বিশ্লেষণ কর  ঘ. \"সবিতার দেশপ্রেম কল্যাণীর মাতৃআজ্ঞার সাথে একই সূত্রে গাথা  \"- উক্তিটির যথার্থতা বিচার কর  সমাধান: ক. অনুপমের বন্ধু হরিশ কানপুরে কাজ করে  খ. শস্তুনাথ সেন আলোচ্য উক্তির মধ্য দিয়ে একজোড়া এয়ারিং সেকরার হাতে দিয়ে তা খাঁটি সোনার কি না পরখ করে দেখতে বলেছেন  \\'অপরিচিতা\\' গল্পের অনুপমের সঙ্গে শস্তুনাথ সেনের কন্যা কল্যাণীর বিয়ে ঠিক কল্যাণীর শরীর থেকে খুলে পরীক্ষা করান অনুপমের মামা  তখন শন্তুনাথ সেন এক জোড়া এয়ারিং এগিয়ে দেন সেকরার হাতে তা পরখ করে দেখার জন্য  কেননা সেটা ছিল অনুপমের মামার দেওয়া বিলাতি জিনিস, যাতে সোনার ভাগ আছে সামান্যই  গ. \"উদ্দীপকের \\'সবিতা\\' ও \\'অপরিচিতা\\' গল্পের \\'কল্যাণী\\' উভয়েই যৌতুকের শিকার \"- মন্তব্যটি যথার্থ  যৌতুকপ্রথা একটি সামাজিক ব্যাধি  এটি আমাদের সমাজে ভয়াল রূপ ধারণ করেছে  বরপক্ষের দাবি পূরণ করতে কন্যার পিতাকে কখনো কখনো সর্বস্বান্ত হতে হয়  বিয়েতে যারা যৌতুক দাবি করে তারা আত্মসম্মানবোধহীন অমানবিক প্রকৃতির লোক  উদ্দীপকে যৌতুকের জন্য বিয়ে ভেঙে যাওয়া এবং যৌতুক দিয়ে বিয়ে না করে আত্মনির্ভরশীল হয়ে মানবকল্যাণে আত্মনিবেদনের দিকটি প্রতিফলিত হয়েছে  এখানে যৌতুককে প্রত্যাখ্যান করে বিয়ে না করার সিদ্ধান্তে সবিতার অটল থাকার কথা বলা হয়েছে  উদ্দীপকের এ বিষয়টি \\'অপরিচিতা\\' গল্পের কল্যাণীর বিয়ে 43')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility function to preview OCR results before full processing\n",
    "def preview_ocr_extraction(\n",
    "    pdf_path: str = \"Data/HSC26-Bangla1st-Paper.pdf\", \n",
    "    page_num: int = 0, \n",
    "    dpi: int = 300\n",
    "):\n",
    "    \"\"\"\n",
    "    Preview OCR extraction results for a specific page\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Previewing OCR extraction for page {page_num + 1}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Extract text using OCR\n",
    "    raw_text = extract_text_with_ocr(pdf_path, page_num, dpi)\n",
    "    cleaned_text = preprocess_bengali_text(raw_text)\n",
    "    \n",
    "    print(f\"📄 Raw text length: {len(raw_text)} characters\")\n",
    "    print(f\"🧹 Cleaned text length: {len(cleaned_text)} characters\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"📝 Raw OCR Output (first 500 chars):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(raw_text[:500])\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✨ Cleaned Text (first 500 chars):\")\n",
    "    print(\"-\" * 40)\n",
    "    print(cleaned_text[:500])\n",
    "    \n",
    "    return raw_text, cleaned_text\n",
    "\n",
    "# Test OCR on first page\n",
    "preview_ocr_extraction(\"Data/HSC26-Bangla1st-Paper.pdf\", page_num=42, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3007d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bengali_rag_chain_labse(use_gpu: bool = False):\n",
    "    \"\"\"\n",
    "    Create RAG chain optimized for Bengali language using LaBSE embeddings\n",
    "    \n",
    "    Args:\n",
    "        use_gpu: Whether to use GPU for embeddings (requires CUDA)\n",
    "    \"\"\"\n",
    "    # Use OpenAI GPT model with Bengali-optimized settings\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4\",  # GPT-4 has better multilingual support\n",
    "        temperature=0.2,  # Lower temperature for more consistent Bengali responses\n",
    "        max_tokens=1500   # More tokens for Bengali responses\n",
    "    )\n",
    "    \n",
    "    # Bengali-optimized prompt template\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        আপনি একজন সহায়ক বাংলা ভাষার সহায়ক। শুধুমাত্র নিম্নলিখিত প্রসঙ্গের উপর ভিত্তি করে প্রশ্নের উত্তর দিন।\n",
    "        যদি আপনি উত্তর না জানেন, তাহলে বলুন \"এই প্রশ্নের জন্য কোনো প্রসঙ্গ পাওয়া যায়নি: {input}\"।\n",
    "        \n",
    "        You are a helpful Bengali language assistant. Answer the question based only on the following context.\n",
    "        If you don't know the answer, reply \"No context available for this question: {input}\".\n",
    "        \n",
    "        প্রশ্ন / Question: {input}\n",
    "        প্রসঙ্গ / Context: {context}\n",
    "        \n",
    "        উত্তর / Answer:\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Load vector store with LaBSE embeddings\n",
    "    print(f\"🔄 Loading vector store with LaBSE embeddings...\")\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/LaBSE\",\n",
    "        model_kwargs={\n",
    "            'device': 'cuda' if use_gpu else 'cpu',\n",
    "            'trust_remote_code': False\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            'normalize_embeddings': True,\n",
    "            'batch_size': 16,\n",
    "            # 'show_progress_bar': False  # Disable progress bar for queries\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    vector_store = Chroma(\n",
    "        persist_directory=\"./bengali_chroma_db_labse\", \n",
    "        embedding_function=embedding\n",
    "    )\n",
    "\n",
    "    # Create retriever with optimized settings for LaBSE\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\",\n",
    "        search_kwargs={\n",
    "            \"k\": 5,  # Retrieve more documents for better context\n",
    "            \"score_threshold\": 0.3,  # Higher threshold for LaBSE (normalized embeddings)\n",
    "        },\n",
    "    )\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(model, prompt)\n",
    "    chain = create_retrieval_chain(retriever, document_chain)\n",
    "    \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fb5fe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_in_bengali_labse(query: str, use_gpu: bool = False):\n",
    "    \"\"\"\n",
    "    Ask questions in Bengali or English and get responses using LaBSE embeddings\n",
    "    \n",
    "    Args:\n",
    "        query: The question to ask\n",
    "        use_gpu: Whether to use GPU for embeddings (requires CUDA)\n",
    "    \"\"\"\n",
    "    # Preprocess the query\n",
    "    processed_query = preprocess_bengali_text(query)\n",
    "    \n",
    "    # Create the chain with LaBSE embeddings\n",
    "    chain = create_bengali_rag_chain_labse(use_gpu=use_gpu)\n",
    "    \n",
    "    # Invoke chain\n",
    "    result = chain.invoke({\"input\": processed_query})\n",
    "    \n",
    "    # Print results\n",
    "    print(\"উত্তর / Answer:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(result[\"answer\"])\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"সূত্র / Sources:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, doc in enumerate(result[\"context\"], 1):\n",
    "        print(f\"{i}. Source: {doc.metadata['source']}\")\n",
    "        if 'page' in doc.metadata:\n",
    "            print(f\"   Page: {doc.metadata['page']}\")\n",
    "        if 'embedding_model' in doc.metadata:\n",
    "            print(f\"   Embedding Model: {doc.metadata['embedding_model']}\")\n",
    "        print(f\"   Content preview: {doc.page_content[:100]}...\")\n",
    "        print()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "469404f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional utility function to search similar documents using LaBSE embeddings\n",
    "def search_similar_bengali_content_labse(query: str, k: int = 3, use_gpu: bool = False):\n",
    "    \"\"\"\n",
    "    Search for similar Bengali content without generating answers using LaBSE embeddings\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        k: Number of results to return\n",
    "        use_gpu: Whether to use GPU for embeddings\n",
    "    \"\"\"\n",
    "    embedding = HuggingFaceEmbeddings(\n",
    "        model_name=\"sentence-transformers/LaBSE\",\n",
    "        model_kwargs={\n",
    "            'device': 'cuda' if use_gpu else 'cpu',\n",
    "            'trust_remote_code': False\n",
    "        },\n",
    "        encode_kwargs={\n",
    "            'normalize_embeddings': True,\n",
    "            'batch_size': 16,\n",
    "            # 'show_progress_bar': False\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    vector_store = Chroma(\n",
    "        persist_directory=\"./bengali_chroma_db_labse\", \n",
    "        embedding_function=embedding\n",
    "    )\n",
    "    \n",
    "    docs = vector_store.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"অনুসন্ধানের ফলাফল / Search Results for: '{query}'\")\n",
    "    print(f\"Using LaBSE embeddings (multilingual BERT)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"\\n{i}. Source: {doc.metadata['source']}\")\n",
    "        if 'page' in doc.metadata:\n",
    "            print(f\"   Page: {doc.metadata['page']}\")\n",
    "        if 'embedding_model' in doc.metadata:\n",
    "            print(f\"   Embedding Model: {doc.metadata['embedding_model']}\")\n",
    "        print(f\"   Content: {doc.page_content[:200]}...\")\n",
    "        print(\"-\" * 40)\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbbee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "অনুসন্ধানের ফলাফল / Search Results for: 'আমি আশা'\n",
      "Using OpenAI embedding model: text-embedding-3-small\n",
      "============================================================\n",
      "\n",
      "1. Source: Data/HSC26-Bangla1st-Paper.pdf\n",
      "   Page: 17\n",
      "   Embedding Model: text-embedding-3-small\n",
      "   Content: ? না, কোনো কালেই না  আমার মনে আছে, কেবল সেই এক রাত্রির অজানা কণ্ঠের মধুর সুরের আশা-জায়গা আছে  নিশ্চয়ই আছে  নইলে দীড়াব কোথায়  তাই বৎসরের পর বৎসর যায় আমি এইখানেই আছি  দেখা হয়, সেই কণ্ঠ শুনি, যখন স...\n",
      "----------------------------------------\n",
      "\n",
      "2. Source: Data/HSC26-Bangla1st-Paper.pdf\n",
      "   Page: 16\n",
      "   Embedding Model: text-embedding-3-small\n",
      "   Content: “না, আপনি যাইতে পারিবেন না, যেমন আছেন বসিয়া থাকুন ” করা, এ কথা মিথ্যা কথা ” বলিয়া নাম লেখা টিকিটটি খুলিয়া প্ল্যাটফর্মে ছুঁড়িয়া ফেলিয়া দিল  করা, এ কথা মিথ্যা কথা ” বলিয়া নাম লেখা টিকিটটি খুলিয়া...\n",
      "----------------------------------------\n",
      "\n",
      "3. Source: Data/HSC26-Bangla1st-Paper.pdf\n",
      "   Page: 17\n",
      "   Embedding Model: text-embedding-3-small\n",
      "   Content: মামার নিষেধ অমান্য করিয়া, মাতৃ-আজ্ঞা ঠেলিয়া, তার পরে আমি কানপুরে আসিয়াছি  কল্যাণীর বাপ এবং কল্যাণীর সঙ্গে দেখা হইয়াছে  হাত জোড় করিয়াছি, মাথা হেট করিয়াছি; শস্তুনাথবাবুর হৃদয় গলিয়াছে  কল্যাণী ব...\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'dpi': 400, 'embedding_model': 'text-embedding-3-small', 'extraction_method': 'OCR', 'page': 17, 'source': 'Data/HSC26-Bangla1st-Paper.pdf', 'start_index': 825}, page_content='? না, কোনো কালেই না  আমার মনে আছে, কেবল সেই এক রাত্রির অজানা কণ্ঠের মধুর সুরের আশা-জায়গা আছে  নিশ্চয়ই আছে  নইলে দীড়াব কোথায়  তাই বৎসরের পর বৎসর যায় আমি এইখানেই আছি  দেখা হয়, সেই কণ্ঠ শুনি, যখন সুবিধা পাই কিছু তার কাজ করিয়া দিই - আর মন বলে, এই তো জায়গা পাইয়াছি  ওগো অপরিচিতা, তোমার পরিচয়ের শেষ হইল না, শেষ হইবে না; কিন্তু ভাগ্য আমার ভালো, এই তো আমি জায়গা পাইয়াছি  17'),\n",
       " Document(metadata={'dpi': 400, 'embedding_model': 'text-embedding-3-small', 'extraction_method': 'OCR', 'page': 16, 'source': 'Data/HSC26-Bangla1st-Paper.pdf', 'start_index': 0}, page_content='“না, আপনি যাইতে পারিবেন না, যেমন আছেন বসিয়া থাকুন ” করা, এ কথা মিথ্যা কথা ” বলিয়া নাম লেখা টিকিটটি খুলিয়া প্ল্যাটফর্মে ছুঁড়িয়া ফেলিয়া দিল  করা, এ কথা মিথ্যা কথা ” বলিয়া নাম লেখা টিকিটটি খুলিয়া প্ল্যাটফর্মে ছুঁড়িয়া ফেলিয়া দিল  আগে হইতে রিজার্ভ করা, এ কথা মিথ্যা কথা৷” 0 আর দে সন ছুঁড়িয়া ফেলিয়া দিল  _ ইতিমধ্যে আর্দালি-সমেত ইউনিফর্ম-পরা সাহেব WIGS কাছে আসিয়া দীড়াইয়াছে  গাড়িতে সে তার আসবাব উঠাইবার জন্য আর্দালিকে প্রথমে ইশারা করিয়াছিল  তাহার পরে মেয়েটির মুখে তাকাইয়া, তার কথা শুনিয়া, ভাব দেখিয়া, স্টেশন-মাস্টারকে একটু স্পর্শ করিল এবং তাহাকে আড়ালে লইয়া গিয়া কী কথা হইল জানি না  দেখা গেল, মেয়েটি তার দলবল লইয়া আবার একপত্তন চানা- মুঠ খাইতে শুরু করিল, আর আমি লজ্জায় আসিয়া ইহাদিগকে নামাইবার উদ্যোগ করিতে লাগিল  মা তখন আর থাকিতে পারিলেন না  জিজ্ঞাসা করিলেন, “তোমার নাম কী AT” শুনিয়া মা এবং আমি দুজনেই চমকিয়া উঠিলাম  “তিনি এখানকার ডাক্তার, তাহার নাম শস্তুনাথ সেন ” তার পরেই সবাই নামিয়া গেল  16'),\n",
       " Document(metadata={'dpi': 400, 'embedding_model': 'text-embedding-3-small', 'extraction_method': 'OCR', 'page': 17, 'source': 'Data/HSC26-Bangla1st-Paper.pdf', 'start_index': 0}, page_content='মামার নিষেধ অমান্য করিয়া, মাতৃ-আজ্ঞা ঠেলিয়া, তার পরে আমি কানপুরে আসিয়াছি  কল্যাণীর বাপ এবং কল্যাণীর সঙ্গে দেখা হইয়াছে  হাত জোড় করিয়াছি, মাথা হেট করিয়াছি; শস্তুনাথবাবুর হৃদয় গলিয়াছে  কল্যাণী বলে, “আমি বিবাহ করিব না ” কী সর্বনাশ  এ পক্ষেও মাতুল আছে নাকি  তার পরে বুঝিলাম, মাতৃভূমি আছে  সেই বিবাহ-ভাঙার পর হইতে কল্যাণী মেয়েদের শিক্ষার ব্রত গ্রহণ করিয়াছে  কিন্তু, আমি আশা ছাড়িতে পারিলাম না  সেই সুরটি যে আমার হৃদয়ের মধ্যে আজও বাজিতেছে-_-সে যেন কোন ওপারের বাঁশি- আমার সংসারের বাহির হইতে আসিল - সমস্ত সংসারের বাহিরে ডাক দিল  আর, সেই- যে রাত্রির অন্ধকারের মধ্যে আমার কানে আসিয়াছিল “জায়গা আছে”, সে যে আমার চিরজীবনের গানের ধুয়া হইয়া রহিল  তখন আমার বয়স ছিল তেইশ, এখন হইয়াছে সাতাশ  এখনো আশা ছাড়ি নাই, কিন্তু মাতুলকে ছাড়িয়াছি  নিতান্ত এক ছেলে বলিয়া মা আমাকে ছাড়িতে পারেন নাই  তোমরা মনে করিতেছ, আমি বিবাহের আশা করি')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Search for similar content using LaBSE embeddings\n",
    "# search_similar_bengali_content_labse(\"আমি আশা\", k=3, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa316f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading vector store with LaBSE embeddings...\n",
      "উত্তর / Answer:\n",
      "--------------------------------------------------\n",
      "এই প্রশ্নের জন্য কোনো প্রসঙ্গ পাওয়া যায়নি: বিবাহ ভাঙার পর হতে কল্যাণী কোন ব্রত গ্রহণ করে?\n",
      "\n",
      "==================================================\n",
      "সূত্র / Sources:\n",
      "--------------------------------------------------\n",
      "1. Source: Data/HSC26-Bangla1st-Paper.pdf\n",
      "   Page: 46\n",
      "   Embedding Model: LaBSE\n",
      "   Content preview: . বিবাহ ভাঙার পর হতে কল্যাণী কোন ব্রত গ্রহণ করে...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'বিবাহ ভাঙার পর হতে কল্যাণী কোন ব্রত গ্রহণ করে?',\n",
       " 'context': [Document(metadata={'dpi': 400, 'embedding_model': 'LaBSE', 'extraction_method': 'OCR', 'page': 46, 'source': 'Data/HSC26-Bangla1st-Paper.pdf', 'start_index': 1473, 'text_length': 2221}, page_content='. বিবাহ ভাঙার পর হতে কল্যাণী কোন ব্রত গ্রহণ করে')],\n",
       " 'answer': 'এই প্রশ্নের জন্য কোনো প্রসঙ্গ পাওয়া যায়নি: বিবাহ ভাঙার পর হতে কল্যাণী কোন ব্রত গ্রহণ করে?'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask question using LaBSE embeddings\n",
    "ask_in_bengali_labse(\"বিবাহ ভাঙার পর হতে কল্যাণী কোন ব্রত গ্রহণ করে?\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fb818ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Loading vector store with LaBSE embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "উত্তর / Answer:\n",
      "--------------------------------------------------\n",
      "\"এই প্রশ্নের জন্য কোনো প্রসঙ্গ পাওয়া যায়নি: কল্যাণীর পিতার নাম কী?\"\n",
      "\n",
      "==================================================\n",
      "সূত্র / Sources:\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'কল্যাণীর পিতার নাম কী?',\n",
       " 'context': [],\n",
       " 'answer': '\"এই প্রশ্নের জন্য কোনো প্রসঙ্গ পাওয়া যায়নি: কল্যাণীর পিতার নাম কী?\"'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_in_bengali_labse(\"কল্যাণীর পিতার নাম কী?\", use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6664af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Compare LaBSE with other approaches\n",
    "def compare_embedding_approaches(query: str):\n",
    "    \"\"\"\n",
    "    Compare results from LaBSE vs other embedding approaches\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Comparing embedding approaches for query: '{query}'\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Test LaBSE\n",
    "    try:\n",
    "        print(f\"\\n📊 Results using LaBSE (multilingual BERT):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        docs = search_similar_bengali_content_labse(query, k=2, use_gpu=False)\n",
    "        \n",
    "        if docs:\n",
    "            print(f\"✅ Found {len(docs)} results with LaBSE\")\n",
    "        else:\n",
    "            print(\"❌ No results found with LaBSE\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error with LaBSE: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"📝 LaBSE Advantages:\")\n",
    "    print(\"   • Specifically designed for multilingual tasks\")\n",
    "    print(\"   • 109+ languages including Bengali\")\n",
    "    print(\"   • No API costs\")\n",
    "    print(\"   • Works offline\")\n",
    "    print(\"   • Normalized embeddings for better similarity\")\n",
    "\n",
    "# Test comparison (uncomment to run)\n",
    "# compare_embedding_approaches(\"কল্যাণী\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
